---
title: "hw2"
author: "Sai Pranith Bhagavatula"
date: "2024-04-20"
output: html_document
---


#Q.1 
```{r}
set.seed(123)

churn <- read.csv("Churn.csv")
sampled_churn <- sample(nrow(churn), 0.7 * nrow(churn)) 

churn_train <- churn[sampled_churn, ]
churn_test <- churn[-sampled_churn, ]


```

#Q.2

```{r}
#library(caret)
#library(lattice)

log_reg_model <- glm(Churn ~ Int.l.Plan + Intl.Calls, data = churn_train, family = "binomial")
summary(log_reg_model)

```

*It can be observed that the customers with the International plan are more likely to churn (almost twice as likely) as opposed to those who do not hold a plan. This observation can be made from the coefficient 1.98 and a very low p-value, it can be observed that the parameter is significant*

*It can also be observed that the more number of international calls made, the lesser will be the chances of churning.It can also be observed that the parameter is significant, based on the significantly low p-value*


#Q.3 

```{r}
library(pROC)

log_reg_model <- glm(Churn ~ ., data = churn_train, family = "binomial")

pred <- predict(log_reg_model, newdata = churn_test, type = "response")

pred_classif <- ifelse(pred > 0.5, TRUE, FALSE)
accuracy_log_reg <- sum(pred_classif == churn_test$Churn) / length(churn_test$Churn)

confusion_matrix <- table(pred > 0.5, churn_test$Churn)

sensitivity_log_reg <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
specificity_log_reg <- confusion_matrix[1, 1] / sum(confusion_matrix[1, ])
auc_log_reg <- roc(churn_test$Churn, pred)$auc

library(class)
library(rpart)
library(rpart.plot)
library(pROC)
library(caret)
library(e1071)
library(randomForest)

numFolds <- trainControl(method = "cv", number = 10)
kGrid <- expand.grid(k = seq(1, 20, 1))

churn_train$Churn <- as.factor(churn_train$Churn)
churn_test$Churn <- as.factor(churn_test$Churn)

knn_model <- train(as.factor(Churn) ~ ., data = churn_train, method = "knn", trControl = numFolds, tuneGrid = kGrid)

knn_pred_churn <- predict(knn_model, newdata = churn_test, method = "knn", k = 3, prob = FALSE)

accuracy_knn <- sum(knn_pred_churn == churn_test$Churn) / length(churn_test$Churn)

knn_matrix <- confusionMatrix(knn_pred_churn, churn_test$Churn)
conf_mat_knn <- knn_matrix$table

sensitivity_knn <- conf_mat_knn[2, 2] / (conf_mat_knn[2, 2] + conf_mat_knn[2, 1])

specificity_knn <- conf_mat_knn[1, 1] / (conf_mat_knn[1, 1] + conf_mat_knn[1, 2])

knn_roc <- roc(response = churn_test$Churn, predictor = as.numeric(knn_pred_churn))
knn_auc <- auc(knn_roc, partial.auc = c(1, 0.5))

# Construct and evaluate the CART model
model_cart <- rpart(Churn ~ ., data = churn_train, method = "class")
pred_cart <- predict(model_cart, churn_test, type = "class")

accuracy_cart <- sum(pred_cart == churn_test$Churn) / length(churn_test$Churn)

conf_matrix <- confusionMatrix(pred_cart, churn_test$Churn)
conf_mat_cart <- conf_matrix$table

sensitivity_cart <- conf_mat_cart[2, 2] / (conf_mat_cart[2, 2] + conf_mat_cart[2, 1])

specificity_cart <- conf_mat_cart[1, 1] / (conf_mat_cart[1, 1] + conf_mat_cart[1, 2])

CART_roc <- roc(response = churn_test$Churn, predictor = as.numeric(pred_cart))
CART_auc <- auc(CART_roc, partial.auc = c(1, 0.5))

model_rf <- randomForest(Churn ~ ., data = churn_train)
pred_rf <- predict(model_rf, churn_test)

accuracy_rf <- sum(pred_rf == churn_test$Churn) / length(churn_test$Churn)

rf_matrix <- confusionMatrix(pred_rf, churn_test$Churn)$table
conf_mat_rf <- rf_matrix

sensitivity_rf <- conf_mat_rf[2, 2] / (conf_mat_rf[2, 2] + conf_mat_rf[2, 1])

specificity_rf <- conf_mat_rf[1, 1] / (conf_mat_rf[1, 1] + conf_mat_rf[1, 2])

auc_rf <- auc(roc(churn_test$Churn, as.numeric(pred_rf)))

results <- data.frame(
  Algorithm = c("LOGISTIC", "CART", "KNN", "RF"),
  Accuracy = c(accuracy_log_reg, accuracy_cart, accuracy_knn, accuracy_rf),
  Sensitivity = c(sensitivity_log_reg, sensitivity_cart, sensitivity_knn, sensitivity_rf),
  Specificity = c(specificity_log_reg, specificity_cart, specificity_knn, specificity_rf),
  AUC = c(auc_log_reg, CART_auc, knn_auc, auc_rf)
)

print(results)

```

#Q.4 

Logistic Regression:
Comments: All the values, accuracy (86.6%), specificity, sensitivity and AUC are decent and moderately fitting as compared to the baseline model.

Decision Tree (CART):
Comments: Great accuracy (93.6%), specificity and sensitivity, but relatively much lower AUC.

K-Nearest Neighbors (KNN):
Comments: Decent accuracy (87.8%), specificity and sensitivity, but a very low AUC.

Random Forest (RF):
Comments: Highest accuracy (95.1%), high values of sensitivity, specificity and AUC. Significantly outperforms the baseline model.


#Q.5 

1. Cross-Validation: In the cases as above, we can observe that overfitting could be an issue, which can be prevented using cross-validation, which provides a robust estimate of the model's performance on a fresh, unseen test data.

2. Hyperparameter Optimization: This method finds a tuple of hyperparameters that yields an optimal modelwhich will minimize a predefined loss function of given independent data.

# Q.6

```{r}
reduced_columns <- names(churn) %in% c("Int.l.Plan","Churn","VMail.Plan","CustServ.Calls") 

reduced_data = churn[reduced_columns]
head(reduced_data)
summary(reduced_data)

```


```{r}
reduced_data$CustServ.Calls=as.factor(reduced_data$CustServ.Calls)
library("arules")
data.trans=as(reduced_data,"transactions")
library("arules")
rules=apriori(data.trans, parameter = list(support =
0.01, confidence = 0.05, target = "rules"))
rules
rules.sorted=sort(rules, by="lift")
inspect(rules.sorted)
rules_df <- data.frame(inspect(rules.sorted))      
write.csv(rules_df,"rules.csv",row.names = FALSE) 

rules_sorted <- sort(rules, by = "confidence", decreasing = TRUE)

highest_confidence_rule <- rules_sorted[1]

inspect(highest_confidence_rule)

```
a. Customers churning without an international plan or any customer service calls are ineligible for a voicemail plan.

b. The support percentage is 0.01560156.

c. The confidence percentage is 0.9811321.

d. The lift value is 1.356331.

# Q.7

```{r}
library("arules")


rules <- apriori(data.trans, parameter = list(support = 0.01, confidence = 0.05, target = "rules"))

rules_sorted <- sort(rules, by = "lift")
inspect(rules_sorted)

rules_df <- as(rules_sorted, "data.frame")

str(rules_df)


write.csv(rules_df, "rules.csv", row.names = FALSE)

filtered_data <- subset(rules_df, grepl("Churn", rules))

sorted_data <- filtered_data[order(-filtered_data$confidence), ]

print(sorted_data)

```

a.Antecedent and consequent (interpret this rule):
The people who are making service calls more than 5 are churning.

b. Support is 0.01200120%.

c. Confidence is 0.60606061%.

d. Lift is 4.1821946

#Q.8


```{r, EXCLUDE=TRUE}
Cereal <- read.csv("C:/Users/hi/OneDrive/Desktop/homework/cereals.csv", stringsAsFactors = TRUE)

numeric_cols = Cereal[, c("Calories", "Protein", "Fat", "Sodium", "Fiber", "Carbo", "Sugars", "Potass", "Vitamins")]
numeric_cols = na.omit(numeric_cols)
distance = dist(numeric_cols, method = "euclidean")
Cereals.std = sapply(numeric_cols, scale)
scaled = scale(numeric_cols)
kmeans_results = kmeans(scaled, centers = 3)
Cereal$cluster <- NA  # Initialize cluster column with NA values
Cereal[rownames(numeric_cols), "cluster"] <- kmeans_results$cluster
```

# Q.9

```{r}
centers <- kmeans_results$centers

clusters <- kmeans_results$cluster

for (i in 1:3) {
  cat("Cluster", i, ":\n")
  cat("Number of cereals in cluster:", sum(kmeans_results$cluster == i), "\n")
  cat("Cluster Center:\n")
  print(centers[i, ])
  cat("\n")
}

```

